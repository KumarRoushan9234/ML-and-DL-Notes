{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solSbWn1HinG"
      },
      "source": [
        "\n",
        "Machine Learning :\n",
        "Machine Learning is a subset of AI that enables systems to **learn patterns from data** and make **predictions or decisions** without explicit programming.\n",
        "\n",
        "- Feed historical data ‚ûù train an algorithm ‚ûù get a model ‚ûù make predictions or classifications on unseen data.\n",
        "\n",
        "\n",
        " ### Use-Cases:\n",
        "- Prediction (e.g., sales forecast)\n",
        "- Classification (e.g., spam detection)\n",
        "- Clustering (e.g., customer segmentation)\n",
        "- Recommendation systems\n",
        "- Anomaly detection\n",
        "- Optimization\n",
        "\n",
        "---\n",
        "## Categories of ML Models :\n",
        "\n",
        "### 1. Supervised Learning :\n",
        "- **Definition**: Learn from labeled data (input-output pairs)\n",
        "- **Goal**: Predict the output for new/unseen inputs\n",
        "- **Examples**: Classification & Regression\n",
        "\n",
        "**Common Models**:\n",
        "- Linear Regression\n",
        "- Logistic Regression\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Decision Trees\n",
        "- Random Forest\n",
        "- Support Vector Machines (SVM)\n",
        "- Gradient Boosting (XGBoost, LightGBM)\n",
        "\n",
        "**Use-Cases**:\n",
        "- Spam detection\n",
        "- House price prediction\n",
        "- Medical diagnosis\n",
        "- Stock market prediction\n",
        "\n",
        "\n",
        "---\n",
        "### 2. **Unsupervised Learning**\n",
        "- **Definition**: Learn patterns from **unlabeled data**\n",
        "- **Goal**: Discover hidden patterns or groupings\n",
        "\n",
        "**Common Models**:\n",
        "- K-Means Clustering\n",
        "- Hierarchical Clustering\n",
        "- DBSCAN\n",
        "- Principal Component Analysis (PCA)\n",
        "\n",
        "**Use-Cases**:\n",
        "- Customer segmentation\n",
        "- Anomaly detection\n",
        "- Dimensionality reduction\n",
        "- Topic modeling\n",
        "\n",
        "---\n",
        "### 3. **Semi-Supervised Learning**\n",
        "- **Definition**: Combination of labeled and unlabeled data\n",
        "- **Use-Case**: When labeling data is expensive\n",
        "\n",
        "**Common Algorithms**: Self-training, label propagation  \n",
        "**Use-Cases**:\n",
        "- Fraud detection\n",
        "- Web content classification\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Reinforcement Learning**\n",
        "- **Definition**: Learn by interacting with the environment using **reward and punishment**\n",
        "- **Goal**: Maximize cumulative reward\n",
        "\n",
        "**Common Algorithms**:\n",
        "- Q-Learning\n",
        "- Deep Q-Networks (DQN)\n",
        "- Policy Gradient Methods\n",
        "\n",
        "**Use-Cases**:\n",
        "- Game AI (AlphaGo)\n",
        "- Robotics  \n",
        "- Autonomous vehicles\n",
        "- Trading bots\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Types of Machine Learning Models\n",
        "\n",
        "### 1. **Classification Models**  \n",
        "**Goal**: Predict a category/label (Discrete output)  \n",
        "**Examples**:\n",
        "- Logistic Regression\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- SVM\n",
        "- Naive Bayes\n",
        "- KNN\n",
        "\n",
        "**Use-Cases**:\n",
        "- Email spam detection\n",
        "- Image classification\n",
        "- Disease diagnosis\n",
        "- Customer churn prediction\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Regression Models**  \n",
        "**Goal**: Predict a continuous numerical value  \n",
        "**Examples**:\n",
        "- Linear Regression\n",
        "- Ridge/Lasso Regression\n",
        "- Decision Tree Regressor\n",
        "- Random Forest Regressor\n",
        "- XGBoost Regressor\n",
        "\n",
        "**Use-Cases**:\n",
        "- House price prediction\n",
        "- Sales forecasting\n",
        "- Temperature prediction\n",
        "- Stock price prediction\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Clustering Models**  \n",
        "**Goal**: Group similar data points (unsupervised)  \n",
        "**Examples**:\n",
        "- K-Means\n",
        "- DBSCAN\n",
        "- Agglomerative Clustering\n",
        "\n",
        "**Use-Cases**:\n",
        "- Customer segmentation\n",
        "- Market basket analysis\n",
        "- Image compression\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Dimensionality Reduction Models**  \n",
        "**Goal**: Reduce features while preserving variance  \n",
        "**Examples**:\n",
        "- PCA (Principal Component Analysis)\n",
        "- t-SNE\n",
        "- LDA (Linear Discriminant Analysis)\n",
        "\n",
        "**Use-Cases**:\n",
        "- Data visualization\n",
        "- Speeding up ML models\n",
        "- Noise reduction\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Ensemble Models**  \n",
        "**Goal**: Combine multiple models to improve performance  \n",
        "**Examples**:\n",
        "- Random Forest (Bagging)\n",
        "- XGBoost, LightGBM (Boosting)\n",
        "- Voting Classifier (Stacking)\n",
        "\n",
        "**Use-Cases**:\n",
        "- Kaggle competitions\n",
        "- Tabular data tasks\n",
        "- Fraud detection\n",
        "- Loan default prediction\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Classical ML Models (Must-Know for Interviews & Projects)\n",
        "\n",
        "| Model                      | Type           | Primary Use-Cases                              | Asked in Interviews? | Core Math / Concepts          |\n",
        "|----------------------------|----------------|------------------------------------------------|----------------------|-------------------------------|\n",
        "| **Linear Regression**      | Supervised     | Predicting continuous values                   | ‚úÖ Always             | Line eq., gradient descent    |\n",
        "| **Logistic Regression**    | Supervised     | Binary classification                          | ‚úÖ Always             | Sigmoid, log loss             |\n",
        "| **K-Nearest Neighbors**    | Supervised     | Classification, regression                     | üî∂ Frequently         | Euclidean distance            |\n",
        "| **Naive Bayes**            | Supervised     | Text/NLP, spam filters                         | üî∂ Frequently         | Bayes' theorem                |\n",
        "| **Decision Tree**          | Supervised     | Classification + Regression                    | ‚úÖ Always             | Entropy, Gini index           |\n",
        "| **Random Forest**          | Ensemble       | Better Decision Tree via Bagging               | ‚úÖ Always             | Bootstrapping, bagging        |\n",
        "| **Support Vector Machine** | Supervised     | High-dimensional classification                | üî∂ Often              | Vectors, hyperplanes, margin  |\n",
        "| **K-Means Clustering**     | Unsupervised   | Grouping unlabeled data                        | üî∂ Often              | Centroids, distance metric    |\n",
        "| **PCA**                    | Dim. Reduction | Feature reduction before ML                    | üî∂ Often              | Eigenvalues/vectors, SVD      |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Advanced ML Models (For Production & Competitive Projects)\n",
        "\n",
        "| Model / Concept              | Type             | Primary Use-Cases                           | Asked in Interviews? | Core Math / Concepts             |\n",
        "|------------------------------|------------------|---------------------------------------------|----------------------|----------------------------------|\n",
        "| **XGBoost / LightGBM / CatBoost** | Ensemble Boosting | Tabular data, Kaggle, production ML         | ‚úÖ Yes, often         | Gradient boosting concepts       |\n",
        "| **Bagging / Boosting**       | Ensemble         | Combine weak learners for strong model      | ‚úÖ Yes                | Bias-variance tradeoff           |\n",
        "| **Stacking / Voting**        | Ensemble         | Combine predictions from multiple models    | üî∏ Sometimes          | Conceptual understanding         |\n",
        "| **Regularization (L1, L2)**  | Optimization     | Prevent overfitting                         | ‚úÖ Always             | Cost function with penalty terms |\n",
        "| **GridSearchCV / RandomSearchCV** | Tuning       | Hyperparameter optimization                 | ‚úÖ Yes                | None (Tool-based)                |\n",
        "| **DBSCAN / Agglomerative**   | Clustering       | Noise-resistant clustering                   | üî∏ Sometimes          | Density, distance-based clusters |\n",
        "| **Isolation Forest**         | Anomaly Detection| Fraud detection, outlier detection          | üî∏ Sometimes          | Random partitioning              |\n",
        "| **Polynomial Regression**    | Supervised       | Modeling nonlinear relationships            | üî∏ Sometimes          | Curve fitting, degree control    |\n",
        "| **Lasso / Ridge / ElasticNet** | Regularized Regression | Shrinking coefficients             | ‚úÖ Yes                | L1/L2 penalties                  |\n",
        "| **Feature Selection Models** | Preprocessing    | Reducing unimportant features               | üî∏ Sometimes          | Variance threshold, Info Gain    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  3. Other Useful Models and Concepts (Nice-to-Know)\n",
        "\n",
        "| Model / Concept            | Category          | Use-Cases                                | Why Important?         | Core Idea                        |\n",
        "|----------------------------|-------------------|------------------------------------------|------------------------|----------------------------------|\n",
        "| **t-SNE / UMAP**           | Visualization     | Plotting high-dimensional data           | Great for presentations| Non-linear dimensionality reduction |\n",
        "| **AutoML (e.g., TPOT)**    | Automation        | Auto model building/tuning               | Used in industry       | Evolutionary search              |\n",
        "| **One-vs-Rest / One-vs-One** | Classification Strategy | Multi-class classification          | Interview design question | Divide multiclass into binary    |\n",
        "| **K-Fold Cross Validation**| Evaluation        | Robust model validation                  | ‚úÖ Always                | Split data for training/testing  |\n",
        "| **ROC/AUC, Precision-Recall** | Evaluation    | Model performance evaluation             | ‚úÖ Always                | Trade-offs, thresholds           |\n",
        "| **Learning Curves**        | Diagnostic Tool   | Detecting under/overfitting              | Interview discussions   | Visual tool                      |\n",
        "| **Bias-Variance Tradeoff** | Theory            | Understanding model generalization       | Core concept            | Low bias + low variance ideal    |\n",
        "\n",
        "---\n",
        "\n",
        "## What to Use When?\n",
        "\n",
        "| Task Type                  | Suggested Model(s)                             |\n",
        "|---------------------------|-------------------------------------------------|\n",
        "| Predict continuous value   | Linear Regression, XGBoost                     |\n",
        "| Classify binary classes    | Logistic Regression, SVM, Random Forest        |\n",
        "| Group customers by behavior| K-Means, DBSCAN                               |\n",
        "| High dimensional data      | PCA, t-SNE                                    |\n",
        "| Real-time fraud detection  | Isolation Forest, XGBoost                     |\n",
        "| Tabular data + competition | XGBoost, LightGBM                             |\n",
        "| NLP tasks                  | Naive Bayes, Logistic Regression              |\n",
        "| Hyperparameter tuning      | GridSearchCV, RandomSearchCV                  |\n",
        "| Anomaly or rare case detection | Isolation Forest, One-Class SVM         |\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
